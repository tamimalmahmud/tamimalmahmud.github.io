<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Tamim Al Mahmud</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <table summary="Table for page layout." id="tlayout">
        <tr valign="top">
            <h1 style="padding-left: 0.5em">Tamim Al Mahmud</h1>
            <hr>
            <td id="layout-menu">
                <div class="menu-item"><a href="index.html">Home</a></div>
                <div class="menu-item"><a href="education.html">Education</a></div>
                <div class="menu-item"><a href="publications.html">Publications</a></div>
                <div class="menu-item"><a href="code.html">Codes & Data</a></div>
                <div class="menu-item"><a href="award.html">Awards & Honours</a></div>
                <div class="menu-item"><a href="voluntary-services.html">Voluntary Services</a></div>
            </td>

            <td id="layout-content">
                <h1 style="margin-top: 0em">Codes & Data</h1>

                <h2>LLM Unlearning: Privacy-Preserving Unlearning for Trustworthy AI</h2>

                <h3>Project Overview</h3>
                <p>
                    LLM Unlearning is an open-source project focused on enabling unlearning techniques in Large Language Models (LLMs). With the rise of AI applications and increasing concerns about data privacy, this project introduces exact and approximate unlearning methods designed to make AI models privacy-preserving, trustworthy, and ethical.
                </p>

                <h3>Key Features</h3>
                <ul>
                    <li><strong>Exact and Approximate Unlearning:</strong> Methods for forgetting specific data efficiently, while preserving model performance.</li>
                    <li><strong>Privacy-Preserving AI:</strong> Secure mechanisms to allow models to forget sensitive data and protect user privacy.</li>
                    <li><strong>Trustworthy AI:</strong> Promotes building ethical models that offer transparency and fairness in data processing.</li>
                </ul>

                <h2>Project 1: DP2Unlearning</h2>
                <p><strong>Github Link:</strong> <a href="https://github.com/tamimalmahmud/LLM-Unlearning/tree/main/DP2Unlearning" target="_blank">DP2Unlearning GitHub</a></p>

                
                <p><strong>Paper: <a href="https://dx.doi.org/10.2139/ssrn.5217160" target="_blank">DP2Unlearning: An Efficient and Guaranteed Unlearning Framework for LLMs</a></strong><br>
                    The DP2Unlearning project focuses on advanced techniques for unlearning within LLMs, offering an efficient and guaranteed framework for LLM unlearning. Navigate to the DP2Unlearning project directory to explore and simulate the results. You can also develop and adapt the methods to your own ideas and research needs.
                </p>
            </td>
        </tr>
    </table>
</body>

</html>
